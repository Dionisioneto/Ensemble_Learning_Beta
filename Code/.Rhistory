if(!require(pacman)) install.packages("pacman"); library(pacman)
p_load(ggplot2,dplyr,geobr, ggplot2, sf,rio,readr)
cadu = read.csv2("https://raw.githubusercontent.com/Dionisioneto/Ensemble_Learning_Beta/master/Data/final_data.csv")
head(cadu)
dim(cadu)
preditoras = cadu %>% subset(select=-c(codigo_ibge,tax,
UF, Município, latitude,
longitude, codigo_uf,siafi_id,
ddd, fuso_horario,capital))
head(preditoras)
cormat = round(cor(preditoras),4)
cadu %>% subset(select=-c(codigo_ibge,tax,
UF, Município, latitude,
longitude, codigo_uf,siafi_id,
ddd, fuso_horario,capital))
preditoras = cadu %>% subset(select=c(ESPVIDA,FECTOT, RAZDEP,
E_ANOSESTUDO, T_ANALF18M,
T_FBBAS, T_FBFUND,
T_FBMED, T_FBSUPER,T_MED18M, T_SUPER25M,
GINI, PIND, PPOB, RDPC1, RDPCT,
THEIL, T_BANAGUA, T_DENS,
T_LIXO, T_LUZ,AGUA_ESGOTO,
T_M10A14CF, T_M15A17CF,
I_ESCOLARIDADE,  IDHM, IDHM_L, IDHM_R))
head(preditoras)
cormat = round(cor(preditoras),4)
head(cormat)
library(reshape2)
melted_cormat <- melt(cormat)
head(melted_cormat)
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
upper_tri <- get_upper_tri(cormat)
upper_tri
colnames(upper_tri) = paste("X", seq(1, dim(upper_tri)[1]), sep = "")
rownames(upper_tri) = paste("X", seq(1, dim(upper_tri)[1]), sep = "")
library(ggplot2)
ggplot(data = melt(upper_tri, na.rm = TRUE), aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "#FF6787", high = "#7286D3", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson \nCorrelation") +
theme_minimal()+
xlab("")+
ylab("")+
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 9, hjust = 1))+
coord_fixed()
brasil_muni = read_municipality(code_muni = "all",year=2010) %>%
select(-c("code_state"))
codigos_abrev <- substr(brasil_muni$code_muni, 1, nchar(brasil_muni$code_muni) - 1)
codigos_full = cbind(as.numeric(brasil_muni$code_muni), as.numeric(codigos_abrev))
colnames(codigos_full) = c("cod_ibge_muni", "shortibge")
codigos_full=as.data.frame(codigos_full)
cadu = left_join(cadu,codigos_full, by = c("codigo_ibge"="shortibge"))
## adicionando ao objeto geom
dfmapa = left_join(brasil_muni,cadu[,c("cod_ibge_muni", "Município","tax")], by = c("code_muni"="cod_ibge_muni"))
ggplot() +
geom_sf(data=dfmapa, aes(fill=tax), color= NA, size=.15)+
labs(title="",
size=8)+
scale_fill_distiller(palette = "RdPu", limits=c(0.3, 1),
name="Rate of beneficiaries",direction = 1)+
theme_minimal()
ggplot() +
geom_sf(data=dfmapa, aes(fill=tax), color= NA, size=.15)+
labs(title="",
size=8)+
scale_fill_distiller(palette = "RdPu", limits=c(0.3, 1),
name="Update rate",direction = 1)+
theme_minimal()
ggplot() +
geom_sf(data=dfmapa, aes(fill=tax), color= NA, size=.15)+
labs(title="",
size=8)+
scale_fill_distiller(palette = "RdPu", limits=c(0.3, 1),
name="Update rate \n",direction = 1)+
theme_minimal()
maptrain = ggplot() +
geom_sf(data=dfmapa,size=1.2,
fill = "grey")+
geom_sf(data=dfmapa[ind_treino,],color="grey",aes(size=0.2),
fill = "steelblue")+
labs(title="",
size=1)+
theme_minimal()
maptest = ggplot() +
geom_sf(data=dfmapa,size=.15,
fill = "grey")+
geom_sf(data=dfmapa[-ind_treino,],size=.05,
fill = "green4")+
labs(title="",
size=8)+
theme_minimal()
set.seed(10) ## for reproducibility
# Training proportion
prop_treino = 0.8
n_treino = round(nrow(datacadu) * prop_treino)
# Training proportion
prop_treino = 0.8
n_treino = round(nrow(cadu) * prop_treino)
ind_treino = sample(1:nrow(cadu), n_treino)
maptrain = ggplot() +
geom_sf(data=dfmapa,size=1.2,
fill = "grey")+
geom_sf(data=dfmapa[ind_treino,],color="grey",aes(size=0.2),
fill = "steelblue")+
labs(title="",
size=1)+
theme_minimal()
maptest = ggplot() +
geom_sf(data=dfmapa,size=.15,
fill = "grey")+
geom_sf(data=dfmapa[-ind_treino,],size=.05,
fill = "green4")+
labs(title="",
size=8)+
theme_minimal()
gridExtra::grid.arrange(maptrain,maptest,ncol=2)
dev.off()
ggplot() +
geom_sf(data=dfmapa,size=1.2,
fill = "grey")+
geom_sf(data=dfmapa[ind_treino,],color="grey",aes(size=0.2),
fill = "steelblue")+
labs(title="",
size=1)+
theme_minimal()
ggplot() +
geom_sf(data=dfmapa,size=1.2,
fill = "grey")+
geom_sf(data=dfmapa[ind_treino,],color="grey",aes(size=0.2),
fill = "steelblue")+
labs(title="",
size=1)+
theme_minimal()
maptrain = ggplot() +
geom_sf(data=dfmapa,size=1.2,
fill = "grey")+
geom_sf(data=dfmapa[ind_treino,],color="grey",aes(size=0.2),
fill = "steelblue")+
labs(title="",
size=1)+
theme_minimal()
maptest = ggplot() +
geom_sf(data=dfmapa,size=.15,
fill = "grey")+
geom_sf(data=dfmapa[-ind_treino,],size=.05,
fill = "green4")+
labs(title="",
size=8)+
theme_minimal()
gridExtra::grid.arrange(maptrain,maptest,ncol=2)
dev.off()
ggplot() +
geom_sf(data=dfmapa,size=1.2,
fill = "grey")+
geom_sf(data=dfmapa[ind_treino,],color="grey",aes(size=0.2),
fill = "steelblue")+
labs(title="",
size=1)+
theme_minimal()
ind_treino
ggplot() +
geom_sf(data=dfmapa,size=.15,
fill = "grey")+
geom_sf(data=dfmapa[-ind_treino,],size=.05,
fill = "green4")+
labs(title="",
size=8)+
theme_minimal()
n_treino
round(nrow(cadu) * prop_treino)
nrow(cadu)
nrow(cadu)-round(nrow(cadu) * prop_treino)
timebreg_end-timebreg_inic
## ----
## 02 - Training and Cross-validation for Ensemble methods
## in Beta regression.
## ----
## Data: Demopgrafical covariates of Brazil's municipalities (2010)
## and the rate of update in the CadUnico system (2015) .
## Libraries
if(!require(pacman)) install.packages("pacman"); library(pacman)
p_load(ggplot2,dplyr, betareg, beepr,betaboost,e1071,caret,compiler,gridExtra)
## ---
## 1 - Reading data ====
## ---
cadu = read.csv2("https://raw.githubusercontent.com/Dionisioneto/Ensemble_Learning_Beta/master/Data/final_data.csv")
head(cadu)
## ---
## 2 - Selection of features and target ====
## ---
y = cadu %>% subset(select=c(tax))
X = cadu %>% subset(select=c(ESPVIDA,FECTOT, RAZDEP,
E_ANOSESTUDO, T_ANALF18M,
T_FBBAS, T_FBFUND,
T_FBMED, T_FBSUPER,T_MED18M, T_SUPER25M,
GINI, PIND, PPOB, RDPC1, RDPCT,
THEIL, T_BANAGUA, T_DENS,
T_LIXO, T_LUZ,AGUA_ESGOTO,
T_M10A14CF, T_M15A17CF,
I_ESCOLARIDADE,  IDHM, IDHM_L, IDHM_R))
datacadu = cbind(X,y)
dim(datacadu)
## ---
## 3 - Slipt into training and test data ====
## ---
set.seed(10) ## for reproducibility
# Training proportion
prop_treino = 0.8
n_treino = round(nrow(datacadu) * prop_treino)
ind_treino = sample(1:nrow(datacadu), n_treino)
# Criar conjuntos de treino e teste
treinocadu = datacadu[ind_treino, ]
testecadu = datacadu[-ind_treino, ]
dim(treinocadu);dim(testecadu)
## -----
## 0. Métricas de ajuste
## -----
MSE = function(y,ypred){mean((y - ypred)^2)}
MAE = function(y,ypred){mean(abs(y - ypred))}
R2 = function(y,ypred){
num = sum((y-ypred)^2)
dem =  sum((y-mean(y))^2)
r = 1 - (num/dem)
return(r)
}
## -------
## 1. Modelo de Regressão Beta
## -------
## Verificando qual a melhor função de ligaçãoapresentou o melhor desempenho
linkfun = c("logit", "probit", "cloglog", "cauchit", "log", "loglog")
mse_linkfun = rep(0,length(linkfun))
enableJIT(3)
for(link in linkfun){
breglin = betareg(tax ~.,
data=treinocadu,
link=link)
ypredbreglin = predict(breglin,testecadu)
mse_linkfun[which(linkfun==link)] = MSE(y=testecadu$tax,ypred=ypredbreglin)
}
cbind(linkfun,as.numeric(mse_linkfun))
## A função cauchit apresentou melhor performance (MSE)
timebreg_inic <- Sys.time()
breg = betareg(tax ~.,
data=treinocadu,
link="cauchit")
timebreg_end <- Sys.time()
## Tempo de treinamento
paste("Tempo de treinamento: ", timebreg_end-timebreg_inic)
confint(breg)
#confint(breg)
coef(breg)
getwd()
write.csv2(coef(breg),file="coef_breg.csv")
confint(breg)
write.csv2(confint(breg),file="ci_breg.csv")
#Tune the Random Forest model
#install.packages("randomForest")
library(randomForest)
## Cross-validation in random Forest
timerf_cv_inic <- Sys.time()
OptModelRF=tune(randomForest, tax~.,
data = treinocadu,
ranges=list(ntree = c(25,50,100,500),
maxfeatures = c(5,10,20,25),
maxnodes = c(3,6,9),
tunecontrol = tune.control(cross = 10)))
## Training with the best model
RF_inic <- Sys.time()
mdRFtree = randomForest(tax~.,
data = treinocadu,
ntree = 25,
maxfeatures=25,
maxnodes = 9)
RF_end <- Sys.time()
RF_end-RF_inic
ypredRF = predict(mdRFtree,newdata=testecadu )
## Metricas
MAE(y=testecadu $tax,ypred=ypredRF)
MSE(y=testecadu $tax,ypred=ypredRF)
sqrt(MSE(y=testecadu $tax,ypred=ypredRF))
R2(y=testecadu $tax,ypred=ypredRF)
## Tempo de treinamento
timeRF_end-timeRF_inic
# feature importance
importance(mdRFtree)
# Plot variable importance
varImpPlot(mdRFtree)
# feature importance
tab_feature_importance = importance(mdRFtree)
paste("X", seq(1, dim(upper_tri)[1]), sep = "")
dim(upper_tri)
X
dim(X)
paste("X", seq(1, dim(X)[2]), sep = "")
# feature importance
tab_feaimp = importance(mdRFtree)
tab_feaimp$var = paste("X", seq(1, dim(X)[2]), sep = "")
paste("X", seq(1, dim(X)[2]), sep = "")
tab_feaimp
# feature importance
tab_feaimp = importance(mdRFtree)
tab_feaimp
data.frame(tab_feaimp)
# feature importance
tab_feaimp = importance(mdRFtree)
tab_feaimp = data.frame(tab_feaimp)
tab_feaimp$var = paste("X", seq(1, dim(X)[2]), sep = "")
head(tab_feaimp)
library(ggplot2)
ggplot(tab_feaimp, aes(x = reorder(var, -IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity") +
xlab("Categorias") + ylab("Valores") +
ggtitle("Gráfico de Barras Ordenado") +
theme_minimal()
tab_feaimp
ggplot(tab_feaimp, aes(x = reorder(var, -IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity") +
xlab("Categorias") + ylab("Valores") +
ggtitle("Gráfico de Barras Ordenado") +
theme_minimal() +
theme_minimal()
ggplot(tab_feaimp, aes(x = reorder(var, -IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity") +
xlab("Categorias") + ylab("Valores") +
ggtitle("Gráfico de Barras Ordenado") +
coord_flip() +
theme_minimal()
ggplot(tab_feaimp, aes(x = reorder(var, IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity") +
xlab("Categorias") + ylab("Valores") +
ggtitle("Gráfico de Barras Ordenado") +
coord_flip() +
theme_minimal()
ggplot(tab_feaimp, aes(x = reorder(var, IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity") +
xlab("Feature \n") + ylab("Valores") +
ggtitle("Gráfico de Barras Ordenado") +
coord_flip() +
theme_minimal()
ggplot(tab_feaimp, aes(x = reorder(var, IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity") +
xlab("Feature \n") + ylab("\n Mean Decrease Accuracy") +
ggtitle("Gráfico de Barras Ordenado") +
coord_flip() +
theme_minimal()
ggplot(tab_feaimp, aes(x = reorder(var, IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity") +
xlab("Feature \n") + ylab("\n Mean Decrease Accuracy") +
ggtitle("Gráfico de Barras Ordenado") +
coord_flip() +
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 9, hjust = 1)) +
theme_minimal()
ggplot(tab_feaimp, aes(x = reorder(var, IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity") +
xlab("Feature \n") + ylab("\n Mean Decrease Accuracy") +
ggtitle("Gráfico de Barras Ordenado") +
coord_flip() +
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 9, hjust = 1)) +
theme_minimal()
ggplot(tab_feaimp, aes(x = reorder(var, IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity") +
xlab("Feature \n") + ylab("\n Mean Decrease Accuracy") +
coord_flip() +
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 9, hjust = 1)) +
theme_minimal()
ggplot(tab_feaimp, aes(x = reorder(var, IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity",color="steelblue") +
xlab("Feature \n") + ylab("\n Mean Decrease Accuracy") +
coord_flip() +
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 9, hjust = 1)) +
theme_minimal()
ggplot(tab_feaimp, aes(x = reorder(var, IncNodePurity), y = IncNodePurity)) +
geom_bar(stat = "identity",fill="steelblue") +
xlab("Feature \n") + ylab("\n Mean Decrease Accuracy") +
coord_flip() +
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 9, hjust = 1)) +
theme_minimal()
